#### - [The Curious Case of Neural Text Degeneration](https://arxiv.org/abs/1904.09751) [unpublished](https://openreview.net/forum?id=rygGQyrFvH)
- Brief Description and Key points
  + The paper argues that natural human text may not necessarily be assigned a high probability
  + It proposes a new sampling strategy called Nucleus Sampling which can be seen as an adaptive-k for k-sampling
  + The work largely concerns itself to non-open ended text generation tasks, story, poem generation etc
- Useful Links
  + [Reddit Discussion](https://www.reddit.com/r/MachineLearning/comments/bowknb/worth_reading_the_curious_case_of_neural_text/)
  
